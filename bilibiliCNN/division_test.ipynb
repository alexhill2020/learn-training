{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "dfpos = pd.read_excel(\"购物评论.xlsx\", sheet_name = \"正向\", header=None)\n",
    "dfpos['y'] = 1  #1代表正面评论。\n",
    "dfneg = pd.read_excel(\"购物评论.xlsx\", sheet_name = \"负向\", header=None)\n",
    "dfneg['y'] = 0  #0代表负面评论。\n",
    "df0 = dfpos.append(dfneg, ignore_index = True)  #将dfneg的数据与dfpos的数据合并成一个新表df0。\n",
    "df0 = df0.sample(frac=1).reset_index(drop=True)  #随机打乱行的顺序，并使index（索引）仍按正常排序。\n",
    "    #实验证明，打乱表顺序并没有显著的提高，可能轻微有一点点一点点地提升吧。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% 导入已标注的数据。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "#………………………………2021.05.09用于BERT训练划分训练集、验证集、测试集，对于本分类程序无用………………………………\n",
    "df1 = df0.iloc[:12349,:]  #取df0前16500条。\n",
    "df2 = df0.iloc[12349:16465,:]  #取df016500条之后的数据。\n",
    "df3 = df0.iloc[16465:,:]\n",
    "df2 = df2.reset_index(drop = True)   #重新设置列索引。\n",
    "df3 = df3.reset_index(drop = True)   #重新设置列索引。\n",
    "df1.to_csv(\"pinglun_train.txt\",sep='\\t',index=True,header=None)\n",
    "df2.to_csv(\"pinglun_dev.txt\",sep='\\t',index=True,header=None)\n",
    "df3.to_csv(\"pinglun_test.txt\",sep='\\t',index=True,header=None)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "i = 1\n",
    "for num in df0[0]:\n",
    "    num= len(num)\n",
    "    x.append(num)\n",
    "    y.append(i)\n",
    "    i += 1\n",
    "x = sorted(x,reverse=True)\n",
    "#x\n",
    "plt.bar(x,y)\n",
    "plt.show()\n",
    "#………………………………2021.05.09用于BERT训练划分训练集、验证集、测试集，对于本分类程序无用………………………………\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\YCJ\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.672 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\n#以上等价于：\\ncuttxt = lambda x: \" \".join(jieba.lcut(x)) # 这里不做任何清理工作，以保留情感词。\\ndf0[\"cleantxt\"] = df0[0].apply(cuttxt)  #注意这里的apply方法，是将此函数应用于指定列的每一行中。\\n#编程要高级感，上面一排，仅仅用这两行语句就实现了。\\n'"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cuttxt(x):\n",
    "    word_list = []\n",
    "    for line in x:\n",
    "        wordcut = jieba.lcut(line)\n",
    "        wordcut = ' '.join(wordcut)\n",
    "        word_list.append(wordcut)\n",
    "    return word_list\n",
    "#df0[\"cleantxt\"] = df0[0].apply(cuttxt)  #直接使用这个的话，cleantxt中每一行皆为一个列表。但下面的方法每一行皆为一个字符串。\n",
    "word_cut_list = cuttxt(df0[0])\n",
    "df0['cleantxt'] = word_cut_list\n",
    "#这里处理后的df0有20582行（即20582条评论），3列。\n",
    "'''\n",
    "#以上等价于：\n",
    "cuttxt = lambda x: \" \".join(jieba.lcut(x)) # 这里不做任何清理工作，以保留情感词。\n",
    "df0[\"cleantxt\"] = df0[0].apply(cuttxt)  #注意这里的apply方法，是将此函数应用于指定列的每一行中。\n",
    "#编程要高级感，上面一排，仅仅用这两行语句就实现了。\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% #切分词。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import CountVectorizer  #此为词频矩阵。经实验，用词频矩阵，预测准确率为83%左右。\n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer  #此为关键词矩阵。经实验，用关键词矩阵，预测准确率为88%左右。\n",
    "    #运用支持向量机分类法准确率在91%左右，朴素贝叶斯方法在88%左右，但支持向量机分类法的速度太慢太慢了，基本要慢30倍不止。\n",
    "    #无论是支持向量机分类法，还是朴素贝叶斯分类法，关键词矩阵都强于词频矩阵。\n",
    "    #总体上来说，运用朴素贝叶斯方法和支持向量机的的准确率都相对较低，可能还是要用CNN卷积神经网络？\n",
    "\n",
    "countvec = TfidfVectorizer() # #创建一个CountVectorizer实例，此CountVectorizer类的作用在于创建词袋的数据结构\n",
    "#countvec = CountVectorizer(min_df = 5)  #这里都可以设停止词，参数为 stop_words = 'english' 。对关键词来说，设不设min_df = 5好像没有影响。\n",
    "\n",
    "wordmtx = countvec.fit_transform(df0.cleantxt) #利用上面的实例将数据转化为矩阵。wordmtx为转化后的矩阵。\n",
    "    #这里wordmtx有20582行（即20582条评论），12014列（即在20582条评论中出现次数达5次以上的单词总共有12014个），也就是说每条评论皆是一个高达12014维的稀疏矩阵。\n",
    "\n",
    "    #注意，这里不能先划分数据集，再向量化，因为用的词频矩阵，所以维度不对。必须先统一向量化再划分词频矩阵。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% #将已标注的所有数据转换为词频矩阵或关键词矩阵。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\ntrain_x,test_x,train_y,test_y = train_test_split(train_data,train_target,test_size=0.3,random_state=5)\\ntrain_data：待划分样本数据。\\ntrain_target：待划分样本数据的结果（标签）\\ntest_size：测试数据占样本数据的比例，若整数则样本数量。上例为测试集占30%。\\nrandom_state：设置随机数种子，保证每次都是同一个随机数。若为0或不填，则每次得到数据都不一样\\ntrain_x为训练集的数据，train_y为训练集的结果（即事先标注时打上的标签）。\\ntest_x为训练集的数据，test_y为测试集的结果（即事先标注时打上的标签）。\\n#整个模型训练原理为先对70%的数据进行训练，训练完成后对剩下的30%进行预测，再用预测所得的结果与事先标的结果进行比对，以此得出正确率和训练效果。\\n'"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split   #引入划分训练集和测试集的方法。\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    wordmtx, df0.y, test_size=0.2,random_state = 111) # 这里直接使用上面创造的共20582个向量，每个向量高达12014维的高维稀疏矩阵wordmtx。\n",
    "                                        #random_state = 111是指定一个随机数，每次建模如果随机数一样，则建构的结果也一样。\n",
    "\n",
    "#x_train = countvec.fit_transform(x_train)   #对训练集的数据进行向量矩阵化。\n",
    "#x_test = countvec.fit_transform(x_test)  #对测试集的数据进行向量矩阵化。维度不对，因为用的词频矩阵，先划分后向量化，那两部分的词并不一样。\n",
    "\n",
    "'''\n",
    "train_x,test_x,train_y,test_y = train_test_split(train_data,train_target,test_size=0.3,random_state=5)\n",
    "train_data：待划分样本数据。\n",
    "train_target：待划分样本数据的结果（标签）\n",
    "test_size：测试数据占样本数据的比例，若整数则样本数量。上例为测试集占30%。\n",
    "random_state：设置随机数种子，保证每次都是同一个随机数。若为0或不填，则每次得到数据都不一样\n",
    "train_x为训练集的数据，train_y为训练集的结果（即事先标注时打上的标签）。\n",
    "test_x为训练集的数据，test_y为测试集的结果（即事先标注时打上的标签）。\n",
    "#整个模型训练原理为先对70%的数据进行训练，训练完成后对剩下的30%进行预测，再用预测所得的结果与事先标的结果进行比对，以此得出正确率和训练效果。\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% # 将已标注的数据按特定比例生成训练集和测试集。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]Wall time: 1min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": "SVC(verbose=True)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC  #从sklearn.svm库中引入支持向量机分类法。此方法很慢\n",
    "#from sklearn import naive_bayes  #从sklearn库中引入朴素贝叶斯分类法。此方法很快。\n",
    "    #经实验，用支持向量机分类模式，准确率和召回率都明显更高，皆在92%左右，而朴素贝叶斯皆在88%左右。\n",
    "    #但支持向量机模式太慢了，太慢了。\n",
    "NBmodel=SVC(kernel = 'rbf', verbose = True)\n",
    "#NBmodel = naive_bayes.MultinomialNB()   #创建朴素贝叶斯分类的实例，此实例采用多项式分类法（MultinomialNB）。\n",
    "    #经实验，采用补积ComplementNB分类法的效果跟多项式分类法的效果差不多，皆为88%左右，而伯努利分类法的效果很差，仅有81%左右。\n",
    "%time NBmodel.fit(x_train, y_train)  #用刚创建的分类实例来拟合模型。x_train为训练集的数据，y_train为训练集的结果（已预先标注）。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% #从sklearn库中引入支持向量机分类方法或朴素贝叶斯分类方法，并创建实例，拟合模型。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.49 s\n"
     ]
    }
   ],
   "source": [
    "%time predict_target = NBmodel.predict(x_test)   #用拟合后的NBmodel模型来预测测试集的数据x_test。输出的是预测出来的测试集结果。下面要将此结果与预先标注结果进行对比。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% #进行验证集预测\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集： 0.9928940176131187 ，验证集： 0.9205732329366043\n",
      "Wall time: 37.7 s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<timed eval>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "%time print('训练集：', NBmodel.score(x_train, y_train),'，验证集：', NBmodel.score(x_test, y_test))\n",
    "%time print(classification_report(y_test, NBmodel.predict(x_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% #分别用两中方式来查看准确率。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1条：[0]\n",
      "第2条：[1]\n",
      "第3条：[0]\n",
      "第4条：[1]\n",
      "第5条：[1]\n",
      "第6条：[1]\n",
      "第7条：[1]\n",
      "第8条：[1]\n",
      "第9条：[0]\n",
      "第10条：[1]\n",
      "第11条：[0]\n",
      "第12条：[1]\n",
      "第13条：[0]\n",
      "第14条：[1]\n",
      "第15条：[0]\n",
      "第16条：[1]\n",
      "第17条：[1]\n",
      "第18条：[1]\n",
      "第19条：[0]\n",
      "第20条：[1]\n",
      "第21条：[0]\n",
      "第22条：[0]\n",
      "第23条：[1]\n",
      "第24条：[0]\n",
      "第25条：[1]\n",
      "第26条：[0]\n",
      "第27条：[0]\n",
      "第28条：[1]\n",
      "第29条：[1]\n",
      "第30条：[1]\n",
      "第31条：[0]\n",
      "第32条：[1]\n",
      "第33条：[1]\n",
      "第34条：[0]\n",
      "第35条：[0]\n",
      "第36条：[1]\n",
      "第37条：[1]\n",
      "第38条：[0]\n",
      "第39条：[0]\n",
      "第40条：[0]\n",
      "第41条：[1]\n",
      "第42条：[0]\n",
      "第43条：[1]\n",
      "第44条：[0]\n",
      "第45条：[0]\n",
      "第46条：[0]\n",
      "第47条：[0]\n",
      "第48条：[1]\n",
      "第49条：[1]\n",
      "第50条：[1]\n",
      "第51条：[1]\n",
      "第52条：[1]\n",
      "第53条：[0]\n",
      "第54条：[0]\n",
      "第55条：[0]\n",
      "第56条：[1]\n",
      "第57条：[1]\n",
      "第58条：[1]\n",
      "第59条：[0]\n",
      "第60条：[1]\n",
      "第61条：[0]\n",
      "第62条：[0]\n",
      "第63条：[1]\n",
      "第64条：[0]\n",
      "第65条：[0]\n",
      "第66条：[1]\n",
      "第67条：[1]\n",
      "第68条：[0]\n",
      "第69条：[1]\n",
      "第70条：[1]\n",
      "第71条：[0]\n",
      "第72条：[0]\n",
      "第73条：[1]\n",
      "第74条：[1]\n",
      "第75条：[0]\n",
      "第76条：[0]\n",
      "第77条：[0]\n",
      "第78条：[1]\n",
      "第79条：[1]\n",
      "第80条：[0]\n",
      "第81条：[1]\n",
      "第82条：[1]\n",
      "第83条：[0]\n",
      "第84条：[1]\n",
      "第85条：[1]\n",
      "第86条：[0]\n",
      "第87条：[0]\n",
      "第88条：[0]\n",
      "第89条：[1]\n",
      "第90条：[0]\n",
      "第91条：[1]\n",
      "第92条：[1]\n",
      "第93条：[1]\n",
      "第94条：[0]\n",
      "第95条：[0]\n",
      "第96条：[1]\n",
      "第97条：[0]\n",
      "第98条：[0]\n",
      "第99条：[1]\n",
      "第100条：[0]\n"
     ]
    }
   ],
   "source": [
    "predict_data = pd.read_csv('newTrain.csv', lineterminator='\\n')\n",
    "#countvec.vocabulary_\n",
    "i = 1\n",
    "for line in predict_data['review'][:100]:    #dfpos表中第0列前100个。\n",
    "    words = \" \".join(jieba.lcut(line))\n",
    "    words_vecs = countvec.transform([words]) # 数据需要转换为可迭代的list格式\n",
    "    print(f'第{i}条：{NBmodel.predict(words_vecs)}')\n",
    "    i +=1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% 导入新的数据，用训练过的模型对其进行分类，并打印结果。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}