{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "path_dir = 'E:\\\\PycharmProjects\\\\Demo0410\\\\work_data_liziqi\\\\data'\n",
    "excel_file = 'shenghuo_comments_32741.xlsx'\n",
    "path_file = os.path.join(path_dir,excel_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "filter_df = pd.read_excel(path_file,usecols=['text','user_name','create_time','clean_text','cut_word','pos_word'])\n",
    "filter_df.index = (filter_df.reset_index()).index + 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% #将保存的文件读取为表格\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "word = []\n",
    "for line in filter_df['cut_word']:\n",
    "    line = line.split(' ')\n",
    "    for w in line:\n",
    "        if len(w) > 1:\n",
    "            if w not in word:\n",
    "                word.append(w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(word)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def word_vector(word,line_lists):\n",
    "    word_vector = coo_matrix((len(word),len(word)), dtype=np.int8).toarray()\n",
    "    for line in line_lists:\n",
    "\n",
    "        #去除读取行中的单字符。\n",
    "        line_list = line.split(' ')\n",
    "        nums = []\n",
    "        for w in line_list:\n",
    "            if len(w) > 1:\n",
    "                nums.append(w)\n",
    "\n",
    "        #循环遍历关键词所在位置 设置word_vector计数\n",
    "        i = 0\n",
    "        j = 0\n",
    "        while i<len(nums):         #ABCD共现 AB AC AD BC BD CD加1\n",
    "            j = i + 1\n",
    "            w1 = nums[i]           #第一个单词\n",
    "            while j<len(nums):\n",
    "                w2 = nums[j]       #第二个单词\n",
    "                #从word数组中找到单词对应的下标\n",
    "                k = 0\n",
    "                n1 = 0\n",
    "                while k<len(word):\n",
    "                    if w1==word[k]: #如果是自身与自身，则不做任何操作。\n",
    "                        n1 = k\n",
    "                        break\n",
    "                    k = k +1\n",
    "                #寻找第二个关键字位置\n",
    "                k = 0\n",
    "                n2 = 0\n",
    "                while k<len(word):\n",
    "                    if w2==word[k]:\n",
    "                        n2 = k\n",
    "                        break\n",
    "                    k = k +1\n",
    "                #重点: 词频矩阵赋值 只计算上三角\n",
    "                if n1<=n2:\n",
    "                    word_vector[n1][n2] = word_vector[n1][n2] + 1\n",
    "                else:\n",
    "                    word_vector[n2][n1] = word_vector[n2][n1] + 1\n",
    "                #print n1, n2, w1, w2\n",
    "                j = j + 1\n",
    "            i = i + 1\n",
    "    return word_vector\n",
    "def save_co_word(word,word_vector,excel_name):\n",
    "    res = open(path_dir+'\\\\'+excel_name, \"a+\", encoding='utf-8')\n",
    "    i = 0\n",
    "    while i<len(word):\n",
    "        w1 = word[i]\n",
    "        j = 0\n",
    "        while j<len(word):\n",
    "            w2 = word[j]\n",
    "            #判断两个词是否共现 共现&词频不为0的写入文件\n",
    "            if word_vector[i][j]>0:\n",
    "                #print w1 +\" \" + w2 + \" \"+ str(int(word_vector[i][j]))\n",
    "                res.write(w1 +\" \" + w2 + \" \"+ str(int(word_vector[i][j]))  +  \"\\n\")\n",
    "            j = j + 1\n",
    "        i = i + 1\n",
    "    res.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一回处理完毕\n"
     ]
    }
   ],
   "source": [
    "word_vector = word_vector(word,filter_df['cut_word'][:5])\n",
    "print('第一回处理完毕')\n",
    "save_co_word(word,word_vector,'co_word.txt')\n",
    "print('保存完毕')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}