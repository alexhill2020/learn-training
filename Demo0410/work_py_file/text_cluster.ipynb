{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\pycharmprojects\\demo0410\\venv\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec  #构建词向量模型\n",
    "from gensim import corpora,models\n",
    "from sklearn.cluster import KMeans  #聚类\n",
    "import matplotlib.pyplot as plt  #数据可视化\n",
    "from sklearn.manifold import TSNE  #给数据降维\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "path_dir = 'E:\\\\PycharmProjects\\\\Demo0410\\\\work_data_liziqi\\\\data'\n",
    "excel_file = 'shenghuo_comments_35378.xlsx'\n",
    "path_file = os.path.join(path_dir,excel_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#读取excel表格里的内容，并将要处理的数据转换为list of list。\n",
    "comments_df = pd.read_excel(path_file,index_col=0)\n",
    "cut_word_list = [line.split() for line in comments_df['cut_word'] ]  #将comments_df['cut_word']里的内容变成list of list，line.split()即把字符串分割后变成列表。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  #从文件中读取相关数据。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#生成文档对应的词典和稀疏向量。\n",
    "dictionary = corpora.Dictionary(cut_word_list)  #生成只包含唯一词的词典（即词典内包含要处理的数据中所有去重后的词）。\n",
    "corpus = [dictionary.doc2bow(text) for text in cut_word_list]  #建立每个词的稀疏向量。\n",
    "#建立tf-idf模型并对所需文档计算ft-idf结果。\n",
    "tfidf_model = models.TfidfModel(corpus)  #对每个词进行tf-idf建模。\n",
    "corpus_tfidf = tfidf_model[corpus]  #计算文档中每个词的tf-idf权重。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  #计算要处理数据中每个单词的权重。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "id_list = []\n",
    "for line in cut_word_list:\n",
    "    id = []\n",
    "    for word in line:\n",
    "        id.append(dictionary.token2id[word])\n",
    "    id_list.append(id)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  #将cut_word_list分词列表，转换为对应的id列表。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nprint(word_tfidf[32665])\\nprint(id_list[32665])\\nprint(cut_word_list[32665])\\nprint(corpus_tfidf[32665])\\n'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#下面的比较复杂，要认真看。经过人工反复比对验证，下面的代码没有任何问题。可直接用。\n",
    "def sort_word_tfidf_accord_with_id_list(corpus_tfidf,id_list):\n",
    "    word_tfidf = []\n",
    "    i = 0\n",
    "    while i < len(corpus_tfidf):\n",
    "        vec = []\n",
    "        for id in id_list[i]:  #取出id列表里的每一行。\n",
    "            j = 0  #这里j主要表示循环到第j条line_tfidf，则取此line_tfidf中第j个元素。\n",
    "            for line_tfidf in corpus_tfidf[i]:  #corpus_tfidf[i]本来就是一行，这里的循环是找一行中的单个元素。\n",
    "                if id == line_tfidf[0]:\n",
    "                    tfidf = corpus_tfidf[i][j][1]   #这里i代表corpus_tfidf这个list of list中的第i个list(即一行)，j代表第i个list中的第j个元素，数字1即这第j个元素中的第2个子元素（第1个子元素用0表示）。\n",
    "                j += 1\n",
    "            vec.append(tfidf)\n",
    "        word_tfidf.append(vec)\n",
    "        i += 1\n",
    "    return word_tfidf  #输出的word_tfidf为一个包含各行各单词权重的list of list。\n",
    "#完成此步骤后，word_vec中的各权重即可与cut_word_list中的各词相对应。以下代码可验证。\n",
    "\n",
    "word_tfidf = sort_word_tfidf_accord_with_id_list(corpus_tfidf,id_list)\n",
    "\n",
    "#以下为验证以上步骤的代码。\n",
    "'''\n",
    "print(word_tfidf[32665])\n",
    "print(id_list[32665])\n",
    "print(cut_word_list[32665])\n",
    "print(corpus_tfidf[32665])\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  #利用id列表将corpus_tfidf里各词的关键词权重按cut_word_list里每条评论的分词顺序进行重新排序。其目的是为了与后面经过word2vec转化的向量相乘。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "word_tfidf_narray = []\n",
    "for line in word_tfidf:\n",
    "    line_array = np.array(line,dtype = np.float32)\n",
    "    word_tfidf_narray.append(line_array)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% 将原本为list of list形式的word_tfidf内部元素转换为数组，以备跟句向量相乘。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "'''\n",
    "n_dim = 100  #word2vec词向量的维度。经试验100维最合适。\n",
    "model = Word2Vec(vector_size=n_dim, window=5, workers=10, min_count=1)  #创建向量模型实例。经实验window=5最合适。\n",
    "model.build_vocab(cut_word_list)  #生成词表，注意这里的comment_filtered_dataframe.cut必须为list of list，否则会出错。\n",
    "%time model.train(cut_word_list,total_examples=model.corpus_count,epochs=10)  #在评论集上建模。经试验，迭代10次是效果是最好的。\n",
    "model.save(path_dir + '\\\\' + 'shenghuo_word_vec.mod') #保存模型。2021年5月13日 22:34分保存的模型较完美，下次可以不用训练，直接用。\n",
    "'''\n",
    "\n",
    "model = Word2Vec.load('E:\\PycharmProjects\\Demo0410\\work_data_liziqi\\data\\shenghuo_word_vec.mod') #加载此前训练好的模型。\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  #训练各词的向量，找到最佳训练模型后就不再训练，直接加载，以确保结果的统一性。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "[('无限', 0.8294063806533813),\n ('世人', 0.8289811015129089),\n ('永遠', 0.826871931552887),\n ('心中', 0.8236914873123169),\n ('人与自然', 0.8211705088615417),\n ('永无止境', 0.8190973997116089),\n ('辛勤工作', 0.8030899167060852),\n ('一份', 0.7956673502922058),\n ('保留', 0.7951913475990295),\n ('内心深处', 0.7947517037391663)]"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('美好生活')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理10000条，共35378条。\n",
      "已处理20000条，共35378条。\n",
      "已处理30000条，共35378条。\n"
     ]
    }
   ],
   "source": [
    "with open(path_dir + '\\\\' + 'all_comments_pos_word_pair_88710.json') as file_json:  #从文件中加载词性字典。\n",
    "    pos_word_dict = json.load(file_json)\n",
    "\n",
    "flag_list = ['vn', 'vd','v','a','ad','an','d','t']  #需加权的词性列表。\n",
    "\n",
    "sentences_vec = [] #关键词加权后所有单条评论的平均向量。\n",
    "i = 0\n",
    "while i < len(cut_word_list):\n",
    "    line = cut_word_list[i]   #取cut_word_list的第i行，此时line为第i条评论。\n",
    "    sentence_vec = []\n",
    "    j = 0\n",
    "    for word in line:\n",
    "        word_vec = word_tfidf[i][j] * model.wv[word]\n",
    "        j += 1\n",
    "        for k,v in pos_word_dict.items():\n",
    "            if (k == word) and (v in flag_list): #遍历字典，如果字典某个键与正在处理的单词相同,此单词的词性在指定的flag_list词性列表中。\n",
    "                word_vec = word_vec * 1.1 #则此单词的权重再乘以1.1。\n",
    "        sentence_vec.append(word_vec)\n",
    "    sentences_vec.append(sum(sentence_vec) / len(sentence_vec))\n",
    "    if i == 10000 or i == 20000 or i == 30000:\n",
    "        print(f'已处理{i}条，共{len(cut_word_list)}条。')\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  #计算加权每个词的tf-idf后的句子向量。 代码都手动验证过，计算没有问题。注意：这里要运行很长时间，至少45分钟。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "def list_ndarray_to_list_of_list(sentences_vec):  #定义此函数，将内含数组的list转换为list of list以存储。\n",
    "    sentences_vec_list = []\n",
    "    for ndarray in sentences_vec:\n",
    "        sentences_vec_list.append(ndarray.tolist())\n",
    "    return sentences_vec_list\n",
    "\n",
    "sentences_vec_list = list_ndarray_to_list_of_list(sentences_vec)\n",
    "\n",
    "with open(path_dir + '\\\\' + 'shenghuo_sentences_vec（加词性权重）.json','w') as file:  #存储全部的句向量。\n",
    "    json.dump(sentences_vec_list,file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% #将计算所得的句向量存入json文件，以备后面用。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "'''\n",
    "#with open(path_dir + '\\\\' + 'shenghuo_sentences_vec.json','r') as load_f:\n",
    "#    sentences1_vec = json.load(load_f)\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  #调用最初训练的未加词性权重的句子向量。但经实验证明，加词性权重的比不加的效果好。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SSE = []  # 存放每次结果的误差平方和\n",
    "for k in range(1,16):\n",
    "    estimator = KMeans(n_clusters=k)  # 构造聚类器\n",
    "    estimator.fit(sentences_vec)  #聚类\n",
    "    SSE.append(estimator.inertia_) # estimator.inertia_获取聚类准则的总和\n",
    "X = range(1,16)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('SSE')\n",
    "plt.plot(X,SSE,'o-')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  #利用肘方法确定聚类的簇的个数。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "cluster_num = 11\n",
    "estimator = KMeans(n_clusters=cluster_num) # 构造聚类器，能过上一步骤确定聚类为4簇区分度最明显。\n",
    "estimator.fit(sentences_vec) #聚类。\n",
    "label_pred = estimator.labels_ #获取聚类后的簇标签。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  #利用KMeans方法对所处理数据进行聚类。经肘方法验证，聚6类效果最佳。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "cluster_df = pd.DataFrame(comments_df,columns = ['user_name','text','cut_word',])\n",
    "cluster_df['cluster'] = label_pred\n",
    "cluster_df.to_excel(path_dir + '\\\\' + 'shenghuo_comments_cluster_%d类(加词性权重).xlsx' % cluster_num)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  #将聚类数据存入excel文档。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "#将原高维数据降为2维。\n",
    "tsne = TSNE(n_components=2,init='pca',random_state=0)  #给高维数据降维，主要用于数据可视化。\n",
    "X =  tsne.fit_transform(sentences_vec) #进行数据降维,降成两维"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% 给数据降维并进行数据可视化。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-59-4bde8bbc9393>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrcParams\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'font.sans-serif'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m'SimHei'\u001B[0m\u001B[1;33m]\u001B[0m  \u001B[1;31m#设置字体为SimHei显示中文。\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrcParams\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'axes.unicode_minus'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m  \u001B[1;31m#设置正常显示字符。\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mx0\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mlabel_pred\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m  \u001B[1;31m#提取X列表中所有0聚类的数据。这个还没有搞懂原理，还得再研究。\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mx1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mlabel_pred\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m  \u001B[1;31m#提取X列表中所有1聚类的数据。\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mx2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mlabel_pred\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m]\u001B[0m  \u001B[1;31m#提取X列表中所有2聚类的数据。\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['SimHei']  #设置字体为SimHei显示中文。\n",
    "plt.rcParams['axes.unicode_minus'] = False  #设置正常显示字符。\n",
    "x0 = X[label_pred == 0]  #提取X列表中所有0聚类的数据。这个还没有搞懂原理，还得再研究。\n",
    "x1 = X[label_pred == 1]  #提取X列表中所有1聚类的数据。\n",
    "x2 = X[label_pred == 2]  #提取X列表中所有2聚类的数据。\n",
    "x3 = X[label_pred == 3]  #提取X列表中所有3聚类的数据。\n",
    "x4 = X[label_pred == 4]  #提取X列表中所有4聚类的数据。\n",
    "x5 = X[label_pred == 5]  #提取X列表中所有5聚类的数据。\n",
    "#x6 = X[label_pred == 6]  #提取X列表中所有6聚类的数据。\n",
    "#x7 = X[label_pred == 7]  #提取X列表中所有7聚类的数据。\n",
    "plt.scatter(x0[:, 0], x0[:, 1], c = \"red\", marker='o', label='聚类0')\n",
    "plt.scatter(x1[:, 0], x1[:, 1], c = \"green\", marker='*', label='聚类1')\n",
    "plt.scatter(x2[:, 0], x2[:, 1], c = \"blue\", marker='+', label='聚类2')\n",
    "plt.scatter(x3[:, 0], x3[:, 1], c = \"yellow\", marker='+', label='聚类3')\n",
    "plt.scatter(x4[:, 0], x4[:, 1], c = \"cyan\", marker='+', label='聚类4')\n",
    "plt.scatter(x5[:, 0], x5[:, 1], c = \"magenta\", marker='+', label='聚类5')\n",
    "#plt.scatter(x6[:, 0], x6[:, 1], c = \"black\", marker='+', label='聚类6')\n",
    "#plt.scatter(x7[:, 0], x7[:, 1], c = \"red\", marker='+', label='聚类7')\n",
    "#plt.xlabel('petal length')  #指定x轴的标题为petal length。\n",
    "#plt.ylabel('petal width')  #指定y轴的标题为petal width。\n",
    "plt.title('李子柒视频评论聚类图')  #\n",
    "plt.legend(loc=2)  #指定图例的位置。\n",
    "#plt.savefig('cluster.png')  #保存图片至sin.png。\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  #将降为2维的数据进行可视化。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "#进行DBSACN聚类。\n",
    "db = DBSCAN(eps=2,min_samples=5).fit(sentences_vec)  #默认参数为eps=0.5,min_samples=2，eps值越小，聚类数量越多，min_samples值越大，聚类越多。\n",
    "labels = db.labels_\n",
    "\n",
    "#打印聚类个数，以调整参数。\n",
    "print(len(set(labels)))\n",
    "\n",
    "#将聚类结果存储进excel文件。\n",
    "cluster_DBSCAN_df = pd.DataFrame(comments_df,columns = ['user_name','text','cut_word',])\n",
    "cluster_DBSCAN_df['cluster_DBSCAN'] = labels\n",
    "cluster_DBSCAN_df.to_excel(path_dir + '\\\\' + 'shenghuo_comments_DBSCN_cluster_%d类(加词性权重).xlsx' % len(set(labels)))\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  #采用DBSACN方法聚类。事实证明，DBSCN聚类效果不好，主要表现为一类超级多，其它几类超几少但类之间相似度很高。可能是数据类型原因。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "{'生活': 0,\n '看': 1,\n '知识': 2,\n '视频': 3,\n '这就是': 4,\n '长': 5,\n '无限': 6,\n '日出而作': 7,\n '日落而息': 8,\n '田园生活': 9,\n '美好': 10,\n '生活方式': 11,\n '真正': 12,\n '这才是': 13,\n '多娇': 14,\n '赞': 15,\n '付出': 16,\n '其实': 17,\n '很多': 18,\n '看似': 19,\n '神仙': 20,\n '艰辛': 21,\n '农村': 22,\n '好': 23,\n '怀': 24,\n '干活': 25,\n '扑面而来': 26,\n '生活气息': 27,\n '太美': 28,\n '桃源': 29,\n '出来': 30,\n '拍': 31,\n '真': 32,\n '与世无争': 33,\n '向往': 34,\n '世外桃源': 35,\n '人': 36,\n '羡慕': 37,\n '般的': 38,\n '这种': 39,\n '女孩': 40,\n '诗': 41,\n '过成': 42,\n '原始': 43,\n '状态': 44,\n '越来越': 45,\n '诗意': 46,\n '创造': 47,\n '妹儿': 48,\n '巧手': 49,\n '幺': 50,\n '能干': 51,\n '总是': 52,\n '惬意': 53,\n '去': 54,\n '想': 55,\n '人间': 56,\n '平凡': 57,\n '朴素': 58,\n '努力': 59,\n '很': 60,\n '样子': 61,\n '美': 62,\n '喜欢': 63,\n '这样的生活': 64,\n '制作': 65,\n '手工': 66,\n '厉害': 67,\n '原生态': 68,\n '家里': 69,\n '真的': 70,\n '都': 71,\n '丰富': 72,\n '会': 73,\n '活着': 74,\n '中': 75,\n '关键': 76,\n '感动': 77,\n '梦': 78,\n '看着': 79,\n '好羡慕': 80,\n '梦寐以求': 81,\n '景色': 82,\n '更': 83,\n '美人美': 84,\n '食物': 85,\n '不是': 86,\n '大家': 87,\n '难道': 88,\n '不错': 89,\n '做事': 90,\n '精致': 91,\n '麻利': 92,\n '想要': 93,\n '一辈子': 94,\n '没有': 95,\n '环境': 96,\n '网络': 97,\n '这种生活': 98,\n '诗情画意': 99,\n '有人': 100,\n '使': 101,\n '看出': 102,\n '太': 103,\n '修身养性': 104,\n '安逸': 105,\n '一起': 106,\n '做': 107,\n '姐妹': 108,\n '真让人': 109,\n '压力': 110,\n '身心': 111,\n '地方': 112,\n '好爽': 113,\n '还': 114,\n '钱': 115,\n '需要': 116,\n '闲云野鹤': 117,\n '多姿多彩': 118,\n '媒体': 119,\n '时代': 120,\n '自给自足': 121,\n '感到': 122,\n '让人': 123,\n '轻松': 124,\n '现代人': 125,\n '常人': 126,\n '有钱人': 127,\n '难以想象': 128,\n '平常': 129,\n '拍出': 130,\n '生产': 131,\n '富婆': 132,\n '真不错': 133,\n '妹妹': 134,\n '想做': 135,\n '到底': 136,\n '上班': 137,\n '每天': 138,\n '累': 139,\n '何妨': 140,\n '关注': 141,\n '果断': 142,\n '真令人': 143,\n '令人神往': 144,\n '景物': 145,\n '种瓜得瓜': 146,\n '奇女子': 147,\n '艰苦': 148,\n '女人': 149,\n '懂得': 150,\n '最美': 151,\n '传递': 152,\n '无所不能': 153,\n '朴实': 154,\n '点': 155,\n '仪式': 156,\n '感': 157,\n '悠然见南山': 158,\n '采菊东篱下': 159,\n '如诗如画': 160,\n '未必': 161,\n '精彩': 162,\n '这般': 163,\n '硬是': 164,\n '远方': 165,\n '国宝': 166,\n '竹林': 167,\n '了不起': 168,\n '安静': 169,\n '小柒': 170,\n '嫉妒': 171,\n '恨': 172,\n '一身': 173,\n '娴熟': 174,\n '磨练': 175,\n '无忧无虑': 176,\n '下': 177,\n '渴望': 178,\n '还要': 179,\n '问': 180,\n '生活态度': 181,\n '不': 182,\n '长寿': 183,\n '真心': 184,\n '唯美': 185,\n '好生': 186,\n '寂静': 187,\n '一级': 188,\n '富有': 189,\n '棒': 190,\n '生活品质': 191,\n '马云': 192,\n '想长': 193,\n '感觉': 194,\n '妙': 195,\n '态度': 196,\n '意境': 197,\n '水墨画': 198,\n '里': 199,\n '事': 200,\n '古朴': 201,\n '真是': 202,\n '强大': 203,\n '资金': 204,\n '仙女': 205,\n '农家乐': 206,\n '小': 207,\n '女': 208,\n '汉子': 209,\n '逼出来': 210,\n '刀': 211,\n '耶': 212,\n '确': 213,\n '能耐': 214,\n '姐姐': 215,\n '太棒了': 216,\n '享受': 217,\n '娶': 218,\n '才': 219,\n '故事': 220,\n '一种': 221,\n '想像': 222,\n '脱离现实': 223,\n '远': 224,\n '学': 225,\n '山': 226,\n '座': 227,\n '有矿': 228,\n '真人': 229,\n '一定': 230,\n '不易': 231,\n '实属': 232,\n '生存': 233,\n '细细品味': 234,\n '般': 235,\n '通': 236,\n '假': 237,\n '现在': 238,\n '分享': 239,\n '源于': 240,\n '艺术': 241,\n '高于': 242,\n '尘埃': 243,\n '无': 244,\n '当成': 245,\n '诗歌': 246,\n '鉴赏': 247,\n '简直': 248,\n '人生': 249,\n '共': 250,\n '才子佳人': 251,\n '美品': 252,\n '色香味': 253,\n '后': 254,\n '土豪': 255,\n '退休': 256,\n '应该': 257,\n '度过': 258,\n '认真': 259,\n '看看': 260,\n '过上': 261,\n '小说': 262,\n '山林': 263,\n '归隐': 264,\n '营养': 265,\n '最好': 266,\n '妹子': 267,\n '所有人': 268,\n '了让': 269,\n '想起': 270,\n '挺': 271,\n '自再': 272,\n '辛苦': 273,\n '乐趣': 274,\n '质量': 275,\n '从小': 276,\n '男耕女织': 277,\n '仙人': 278,\n '幸福': 279,\n '慢生活': 280,\n '乡间': 281,\n '理想': 282,\n '采摘': 283,\n '食材': 284,\n '农民': 285,\n '希望': 286,\n '悠闲': 287,\n '梦想': 288,\n '恬淡': 289,\n '温馨': 290,\n '东西': 291,\n '好像': 292,\n '最': 293,\n '老': 294,\n '现实': 295,\n '人间仙境': 296,\n '原于': 297,\n '根本': 298,\n '看到': 299,\n '将来': 300,\n '中国': 301,\n '平平淡淡': 302,\n '真实': 303,\n '普通人': 304,\n '完美': 305,\n '还好': 306,\n '陶冶': 307,\n '有机': 308,\n '极致': 309,\n '此种': 310,\n '仙境': 311,\n '像是': 312,\n '咬': 313,\n '美的': 314,\n '蚊子': 315,\n '充满': 316,\n '心向往之': 317,\n '试问': 318,\n '好似': 319,\n '格调': 320,\n '高': 321,\n '幾天': 322,\n '想去': 323,\n '愜意好': 324,\n '玩': 325,\n '節奏': 326,\n '中国人': 327,\n '理想化': 328,\n '佩服': 329,\n '不会': 330,\n '可惜': 331,\n '和谐': 332,\n '水果': 333,\n '花花草草': 334,\n '蔬菜': 335,\n '齐全': 336,\n '向往已久': 337,\n '写意': 338,\n '抽象': 339,\n '不知': 340,\n '美妙': 341,\n '成仙': 342,\n '美女': 343,\n '一亿': 344,\n '存款': 345,\n '一应俱全': 346,\n '瓜果': 347,\n '更新': 348,\n '等到': 349,\n '终于': 350,\n '安安静静': 351,\n '不了': 352,\n '吃': 353,\n '天天': 354,\n '胖': 355,\n '居士': 356,\n '恬静': 357,\n '这份': 358,\n '以后': 359,\n '有钱': 360,\n '肯定': 361,\n '搬': 362,\n '想望': 363,\n '樱桃': 364,\n '空间': 365,\n '一点': 366,\n '仙': 367,\n '期': 368,\n '没': 369,\n '贴近生活': 370,\n '娴静': 371,\n '却是': 372,\n '只': 373,\n '服': 374,\n '网红': 375,\n '慢节奏': 376,\n '童话': 377,\n '有个': 378,\n '自由自在': 379,\n '花园': 380,\n '花儿': 381,\n '令人': 382,\n '支持': 383,\n '过出': 384,\n '实在': 385,\n '回归自然': 386,\n '王道': 387,\n '小时候': 388,\n '磨豆腐': 389,\n '记忆': 390,\n '乐观': 391,\n '子染': 392,\n '深深感动': 393,\n '积极': 394,\n '带入': 395,\n '彻底': 396,\n '品味': 397,\n '平静': 398,\n '舒服': 399,\n '大自然': 400,\n '贴近': 401,\n '超赞': 402,\n '未来': 403,\n '现代化': 404,\n '一天': 405,\n '好久': 406,\n '认真对待': 407,\n '不行': 408,\n '剧组': 409,\n '没找': 410,\n '正是': 411,\n '满': 412,\n '花': 413,\n '院子': 414,\n '原来': 415,\n '快乐': 416,\n '简单': 417,\n '文化': 418,\n '能带': 419,\n '宁静': 420,\n '祥和': 421,\n '买不到': 422,\n '城里人': 423,\n '小美女': 424,\n '大多数': 425,\n '奶奶': 426,\n '加油': 427,\n '善待': 428,\n '愿': 429,\n '人才': 430,\n '只能': 431,\n '一幅': 432,\n '一首': 433,\n '画': 434,\n '双手': 435,\n '自然': 436,\n '近': 437,\n '不到': 438,\n '懂': 439,\n '气息': 440,\n '艺术家': 441,\n '日子': 442,\n '却': 443,\n '得到': 444,\n '难以': 445,\n '亨': 446,\n '受': 447,\n '心灵美': 448,\n '美景': 449,\n '了像': 450,\n '坏境': 451,\n '方式': 452,\n '遥不可及': 453,\n '安好': 454,\n '心里': 455,\n '忧伤': 456,\n '有种': 457,\n '淡淡的': 458,\n '每次': 459,\n '一段时间': 460,\n '真好': 461,\n '讲': 462,\n '上': 463,\n '争取': 464,\n '六年': 465,\n '幽静': 466,\n '剩': 467,\n '高质': 468,\n '电视': 469,\n '世间': 470,\n '纷扰': 471,\n '远离': 472,\n '女子': 473,\n '千百样': 474,\n '回归': 475,\n '最为': 476,\n '知道': 477,\n '下来': 478,\n '黄磊': 479,\n '别人': 480,\n '太巧': 481,\n '手': 482,\n '梦里': 483,\n '活成': 484,\n '着实': 485,\n '那种': 486,\n '或许': 487,\n '家': 488,\n '李': 489,\n '的确': 490,\n '普': 491,\n '纯': 492,\n '诶': 493,\n '清流': 494,\n '古代': 495,\n '气': 496,\n '隔绝': 497,\n '难': 498,\n '乡村': 499,\n '不敢': 500,\n '同爱': 501,\n '清雅': 502,\n '小姐姐': 503,\n '世外': 504,\n '四川': 505,\n '大': 506,\n '桃园': 507,\n '美食': 508,\n '好看': 509,\n '穿': 510,\n '活': 511,\n '脱俗': 512,\n '爱': 513,\n '改变': 514,\n '超凡脱俗': 515,\n '很美': 516,\n '导师': 517,\n '有趣': 518,\n '妥妥': 519,\n '想象': 520,\n '整个': 521,\n '过程': 522,\n '钱才': 523,\n '清净': 524,\n '实践': 525,\n '心旷神怡': 526,\n '情调': 527,\n '学习': 528,\n '有没有': 529,\n '机会': 530,\n '這': 531,\n '多岁': 532,\n '好好': 533,\n '本源': 534,\n '一份': 535,\n '特': 536,\n '短暂': 537,\n '一下': 538,\n '体验': 539,\n '你好': 540,\n '不过如此': 541,\n '特别': 542,\n '似': 543,\n '清晰': 544,\n '版': 545,\n '电视剧': 546,\n '逍遥': 547,\n '一部': 548,\n '古代人': 549,\n '日常': 550,\n '纪录片': 551,\n '丰富多彩': 552,\n '总': 553,\n '非常': 554,\n '中诗': 555,\n '传说': 556,\n '允许': 557,\n '只不过': 558,\n '干': 559,\n '话': 560,\n '做饭': 561,\n '喧嚣': 562,\n '城市': 563,\n '无奈': 564,\n '社会': 565,\n '估计': 566,\n '饿死': 567,\n '骨感': 568,\n '香': 569,\n '不远': 570,\n '几百万': 571,\n '能够': 572,\n '嚮': 573,\n '太讓人': 574,\n '這樣': 575,\n '了到': 576,\n '内心': 577,\n '形容': 578,\n '无法': 579,\n '言语': 580,\n '回': 581,\n '过得': 582,\n '不起': 583,\n '没钱': 584,\n '真过': 585,\n '快节奏': 586,\n '世上': 587,\n '死': 588,\n '明人': 589,\n '暗话': 590,\n '说': 591,\n '馋': 592,\n '真想': 593,\n '世界': 594,\n '主要': 595,\n '可能': 596,\n '现实生活': 597,\n '画风': 598,\n '也许': 599,\n '前提': 600,\n '手机': 601,\n '离开': 602,\n '见得': 603,\n '大妈': 604,\n '爱看': 605,\n '默默': 606,\n '男人': 607,\n '本身': 608,\n '算': 609,\n '顶多': 610,\n '养大': 611,\n '小羊': 612,\n '肉': 613,\n '滋味': 614,\n '特有': 615,\n '太累': 616,\n '一百多岁': 617,\n '以上': 618,\n '美丽': 619,\n '柒': 620,\n '洗': 621,\n '住': 622,\n '几天': 623,\n '真棒': 624,\n '凡间': 625,\n '日常生活': 626,\n '李寡妇': 627,\n '心驰神往': 628,\n '多么': 629,\n '仙界': 630,\n '欣赏': 631,\n '难得': 632,\n '说心里话': 633,\n '本领': 634,\n '邻居': 635,\n '平和': 636,\n '心态': 637,\n '带来': 638,\n '漂亮': 639,\n '味道': 640,\n '觉得': 641,\n '无拘无束': 642,\n '纷争': 643,\n '问世': 644,\n '世俗': 645,\n '养': 646,\n '养蚕': 647,\n '团队': 648,\n '枯燥': 649,\n '人间烟火': 650,\n '识': 651,\n '甚': 652,\n '买': 653,\n '偶': 654,\n '噶': 655,\n '顾顾': 656,\n '带': 657,\n '文艺': 658,\n '范儿': 659,\n '勾心斗角': 660,\n '仙气': 661,\n '来源于': 662,\n '生于': 663,\n '仙意': 664,\n '十足': 665,\n '子七': 666,\n '累不累': 667,\n '父母': 668,\n '起来': 669,\n '条件': 670,\n '些': 671,\n '喳喳': 672,\n '知知': 673,\n '鸟儿': 674,\n '凡人': 675,\n '在座': 676,\n '绿意': 677,\n '舔': 678,\n '儿': 679,\n '麻辣味': 680,\n '不想': 681,\n '了想': 682,\n '回家': 683,\n '看来': 684,\n '第一次': 685,\n '见': 686,\n '人景': 687,\n '此生': 688,\n '足矣': 689,\n '优美': 690,\n '戏剧': 691,\n '山里': 692,\n '皮肤': 693,\n '童话般': 694,\n '好人': 695,\n '水': 696,\n '静谧': 697,\n '好吃': 698,\n '的看': 699,\n '纯天然': 700,\n '热爱生活': 701,\n '超脱': 702,\n '一日': 703,\n '不用': 704,\n '工作': 705,\n '与世隔绝': 706,\n '人民': 707,\n '全世界': 708,\n '追求': 709,\n '焦虑': 710,\n '享': 711,\n '充实': 712,\n '不怕苦': 713,\n '拍累': 714,\n '修行者': 715,\n '古老': 716,\n '广西': 717,\n '过过': 718,\n '万分': 719,\n '心灵手巧': 720,\n '美美': 721,\n '每个': 722,\n '中比': 723,\n '好想哭': 724,\n '实际': 725,\n '残酷': 726,\n '画面': 727,\n '今天': 728,\n '坐': 729,\n '敢': 730,\n '跟不上': 731,\n '养眼': 732,\n '幸运': 733,\n '区别': 734,\n '悠然自得': 735,\n '心灵': 736,\n '涤荡': 737,\n '融入': 738,\n '城里': 739,\n '姑娘': 740,\n '一过': 741,\n '啥时候': 742,\n '自由': 743,\n '财务': 744,\n '能力': 745,\n '勤劳': 746,\n '聪慧': 747,\n '够': 748,\n '牛': 749,\n '妈呀': 750,\n '成': 751,\n '最佳': 752,\n '诠释': 753,\n '乡景': 754,\n '淋漓': 755,\n '令人羡慕': 756,\n '山野': 757,\n '这辈子': 758,\n '一个亿': 759,\n '过不上': 760,\n '省': 761,\n '老婆': 762,\n '手艺': 763,\n '呆': 764,\n '很久周': 765,\n '期待': 766,\n '女儿': 767,\n '南方': 768,\n '适合': 769,\n '才能': 770,\n '人人': 771,\n '做到': 772,\n '几个': 773,\n '找': 774,\n '普通': 775,\n '你家': 776,\n '天人合一': 777,\n '今后': 778,\n '新': 779,\n '方向': 780,\n '美好生活': 781,\n '乡下': 782,\n '风景': 783,\n '嘿嘿': 784,\n '大山': 785,\n '里面': 786,\n '三顿': 787,\n '忙活': 788,\n '隐居': 789,\n '饭': 790,\n '奢华': 791,\n '年轻人': 792,\n '新时尚': 793,\n '轻': 794,\n '世': 795,\n '安宁': 796,\n '永的': 797,\n '隔离': 798,\n '燃起': 799,\n '两年': 800,\n '舒适': 801,\n '拍成': 802,\n '梦境': 803,\n '愿意': 804,\n '我爱你': 805,\n '了有': 806,\n '木有': 807,\n '这次': 808,\n '贵宾': 809,\n '无憾': 810,\n '片': 811,\n '精灵': 812,\n '生态': 813,\n '年纪轻轻': 814,\n '换': 815,\n '平淡': 816,\n '小农经济': 817,\n '祖宗': 818,\n '生错': 819,\n '咋样': 820,\n '至少': 821,\n '不快': 822,\n '节奏': 823,\n '农家': 824,\n '醇香': 825,\n '风情': 826,\n '田间': 827,\n '枯燥乏味': 828,\n '一辈': 829,\n '婆婆': 830,\n '展示': 831,\n '比较': 832,\n '突然': 833,\n '仰慕': 834,\n '技艺': 835,\n '活得': 836,\n '便是': 837,\n '所谓': 838,\n '神往': 839,\n '还原': 840,\n '园林': 841,\n '缺': 842,\n '多才多艺': 843,\n '有滋有味': 844,\n '优雅': 845,\n '提升': 846,\n '诗画': 847,\n '尝试': 848,\n '人们': 849,\n '值得': 850,\n '一打': 851,\n '妞': 852,\n '无与伦比': 853,\n '食欲': 854,\n '菜': 855,\n '回不去': 856,\n '别致': 857,\n '不同': 858,\n '女性': 859,\n '有着': 860,\n '现代': 861,\n '放弃': 862,\n '王位继承': 863,\n '原味': 864,\n '细致': 865,\n '仙子': 866,\n '孝顺': 867,\n '奢侈': 868,\n '高档': 869,\n '天呀': 870,\n '山水': 871,\n '慢悠悠': 872,\n '整理': 873,\n '节奏快': 874,\n '样': 875,\n '孤单': 876,\n '烟火': 877,\n '咱俩': 878,\n '哥哥': 879,\n '嫁给': 880,\n '十分': 881,\n '上门': 882,\n '女婿': 883,\n '招': 884,\n '足以': 885,\n '伙食': 886,\n '勇气': 887,\n '录制': 888,\n '相': 889,\n '答案': 890,\n '给出': 891,\n '西南': 892,\n '手法': 893,\n '总得': 894,\n '绿': 895,\n '过得去': 896,\n '成都': 897,\n '忍不住': 898,\n '吖': 899,\n '直接': 900,\n '哥': 901,\n '成就': 902,\n '拍照': 903,\n '太好了': 904,\n '大片': 905,\n '得天独厚': 906,\n '人群': 907,\n '格格不入': 908,\n '嘻嘻': 909,\n '所有': 910,\n '所迫': 911,\n '扛下': 912,\n '永远': 913,\n '流传': 914,\n '充實': 915,\n '簡單': 916,\n '綠色': 917,\n '敬佩': 918,\n '班': 919,\n '我心': 920,\n '樂': 921,\n '農家': 922,\n '挺棒': 923,\n '山村': 924,\n '接地': 925,\n '亲近': 926,\n '清静': 927,\n '样样': 928,\n '走': 929,\n '心中': 930,\n '凉': 931,\n '姑': 932,\n '传世': 933,\n '传奇': 934,\n '必将': 935,\n '永久': 936,\n '標準': 937,\n '賢妻': 938,\n '姑奶奶': 939,\n '外': 940,\n '两遍': 941,\n '好个': 942,\n '采菊东': 943,\n '闲适': 944,\n '做菜': 945,\n '人心': 946,\n '迷人': 947,\n '不愧': 948,\n '古': 949,\n '法': 950,\n '真幸福': 951,\n '意': 952,\n '田园诗': 953,\n '不要': 954,\n '来生': 955,\n '慢慢': 956,\n '神仙般': 957,\n '有山有水': 958,\n '才华': 959,\n '爱上你': 960,\n '田园牧歌': 961,\n '美不胜收': 962,\n '交通': 963,\n '基本': 964,\n '自在': 965,\n '甜': 966,\n '大部份': 967,\n '写照': 968,\n '子': 969,\n '年代': 970,\n '忆起': 971,\n '为啥': 972,\n '本该': 973,\n '治愈': 974,\n '天上': 975,\n '帮': 976,\n '立足': 977,\n '真美': 978,\n '本来': 979,\n '无可奈何': 980,\n '身': 981,\n '出身': 982,\n '家庭': 983,\n '背景': 984,\n '道具': 985,\n '五十岁': 986,\n '眷侣': 987,\n '神仙姐姐': 988,\n '应': 989,\n '影视片': 990,\n '点滴': 991,\n '纪录': 992,\n '节目': 993,\n '包装': 994,\n '强': 995,\n '这家': 996,\n '达': 997,\n '漫画': 998,\n '啥子': 999,\n ...}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#未进行词性加权。\n",
    "'''\n",
    "line_word_cut_list_have_flag = comments_df\n",
    "sentences_vec = [] #关键词加权后所有单条评论的平均向量。\n",
    "i = 0\n",
    "while i < len(cut_word_list):\n",
    "    line = cut_word_list[i]   #取cut_word_list的第i行，此时line为第i条评论。\n",
    "    sentence_vec = []\n",
    "    for word in line:\n",
    "        for word_idf in word_tfidf[i]:\n",
    "            word_vec = word_idf * model.wv[word]\n",
    "        sentence_vec.append(word_vec)\n",
    "    sentences_vec.append(sum(sentence_vec) / len(sentence_vec))\n",
    "    if i == 10000 or i == 20000 or i == 30000:\n",
    "        print(f'已处理{i}条，共{len(cut_word_list)}条。')\n",
    "    i += 1\n",
    "'''\n",
    "\n",
    "#进行词性加权。\n",
    "'''\n",
    "#with open(path_dir + '\\\\' + 'all_comments_pos_word_pair_84823.json') as file_json:  #从文件中加载词性字典。\n",
    "#    pos_word_dict = json.load(file_json)\n",
    "\n",
    "flag_list = ['vn', 'vd','v','a','ad','an','d','t']  #需加权的词性列表。\n",
    "\n",
    "sentences_vec = [] #关键词加权后所有单条评论的平均向量。\n",
    "i = 0\n",
    "while i < len(cut_word_list):\n",
    "    line = cut_word_list[i]   #取出第i行。\n",
    "    sentence_vec = []\n",
    "    j = 0  #取出第j个单词。\n",
    "    for word in line:  #执行第1次，则取出0位置的单词(此时j=0)，执行第2次，则取出1位置的单词（第2个，此时j=1）。\n",
    "        word_vec = word_tfidf[i][j] * model.wv[word] #每个词的向量乘以此词的权重。权重：执行第1次的时候，取出第1行第1个单词的权重，执行第6次的时候，取出第1行第6个单词的权重。\n",
    "        j += 1\n",
    "        for k,v in pos_word_dict.items():\n",
    "            if (k == word) and (v in flag_list): #遍历字典，如果字典某个键与正在处理的单词相同,此单词的词性在指定的flag_list词性列表中。\n",
    "               word_vec = word_vec * 1.1 #则此单词的权重再乘以1.1。\n",
    "        sentence_vec.append(word_vec)\n",
    "    sentences_vec.append(sum(sentence_vec) / len(sentence_vec))\n",
    "    if i == 10000 or i == 20000 or i == 30000:\n",
    "        print(f'已处理{i}条，共{len(cut_word_list)}条。')\n",
    "    i += 1\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  #计算加权每个词的tf-idf后的句子向量备份。\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n看似 神仙 生活 其实 付出 很多 艰辛\\n[(0, 0.02354413703260787),\\n (16, 0.43915344808412327),  神仙\\n (17, 0.358712959732896),\\n (18, 0.3215642030674232),\\n (19, 0.5113637160890292),  付出\\n (20, 0.30178812644516056),\\n (21, 0.471107710695582)]  艰辛\\n\\n(4, 17671)\\t0.45968595392489686  看似\\n(4, 15691)\\t0.3199103607197395\\n(4, 15221)\\t0.49269247736983146  生活\\n(4, 14623)\\t0.08949056903126384\\n(4, 8782)\\t0.3362725167502957\\n(4, 3142)\\t0.3669929721838787\\n(4, 2144)\\t0.4333920840440299  艰辛\\n\\n(4, 17671)\\t0.45968595392489686  看似\\n(4, 8782)\\t0.3362725167502957\\n(4, 2144)\\t0.4333920840440299  生活\\n(4, 3142)\\t0.3669929721838787\\n(4, 15691)\\t0.3199103607197395\\n(4, 15221)\\t0.49269247736983146  付出\\n(4, 14623)\\t0.0894905690312638\\n'"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#提取关键词权重第二种方式： 注意，第二种和第三种差不多，只是函数不一样。\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text_list = comments_df['cut_word'].tolist()\n",
    "vectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")  ##这里参数为token_pattern=r\"(?u)\\b\\w+\\b\"，表示不去掉单字符。默认为token_pattern=r\"(?u)\\b\\w\\w+\\b\"，多了一个\\w，表示从2个字符起适配，去掉单字符。\n",
    "x = vectorizer.fit_transform(text_list)\n",
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(x)\n",
    "\n",
    "#提取关键词权重第三种方式：\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "s = comments_df['cut_word'].tolist()\n",
    "tfidf2 = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")  #这里参数为token_pattern=r\"(?u)\\b\\w+\\b\"，表示不去掉单字符。默认为token_pattern=r\"(?u)\\b\\w\\w+\\b\"，多了一个\\w，表示从2个字符起适配，去掉单字符。\n",
    "re = tfidf2.fit_transform(s)\n",
    "'''\n",
    "\n",
    "#三种方式数据对比：第一(genism)最好，其次是第三(sklearn.TfidfVectorizer)，然后是第二（sklearn.CountVectorizer + sklearn.TfidfTransformer）\n",
    "'''\n",
    "看似 神仙 生活 其实 付出 很多 艰辛\n",
    "[(0, 0.02354413703260787),\n",
    " (16, 0.43915344808412327),  神仙\n",
    " (17, 0.358712959732896),\n",
    " (18, 0.3215642030674232),\n",
    " (19, 0.5113637160890292),  付出\n",
    " (20, 0.30178812644516056),\n",
    " (21, 0.471107710695582)]  艰辛\n",
    "\n",
    "(4, 17671)\t0.45968595392489686  看似\n",
    "(4, 15691)\t0.3199103607197395\n",
    "(4, 15221)\t0.49269247736983146  生活\n",
    "(4, 14623)\t0.08949056903126384\n",
    "(4, 8782)\t0.3362725167502957\n",
    "(4, 3142)\t0.3669929721838787\n",
    "(4, 2144)\t0.4333920840440299  艰辛\n",
    "\n",
    "(4, 17671)\t0.45968595392489686  看似\n",
    "(4, 8782)\t0.3362725167502957\n",
    "(4, 2144)\t0.4333920840440299  生活\n",
    "(4, 3142)\t0.3669929721838787\n",
    "(4, 15691)\t0.3199103607197395\n",
    "(4, 15221)\t0.49269247736983146  付出\n",
    "(4, 14623)\t0.0894905690312638\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  #sklearn关键词提取方式备份。\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}